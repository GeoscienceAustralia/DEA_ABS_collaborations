{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabulation of Fractional Cover data within shapefile polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T04:13:20.577632Z",
     "start_time": "2019-02-04T04:13:20.554372Z"
    }
   },
   "source": [
    "**What does this notebook do?**\n",
    "\n",
    "This notebook is a pilot collaboration between Geoscience Australia and Australian Bureau of Statistics. The purpose of the notebook is to use a shapefile polygon boundaries to load fractional cover dataset, complete zonal statistics and tabulate the results.\n",
    "\n",
    "**Requirements**\n",
    "\n",
    "You need to run the following commands from the command line prior to launching jupyter notebooks from the same terminal so that the required libraries and paths are set:\n",
    "\n",
    "`module use /g/data/v10/public/modules/modulefiles`\n",
    "\n",
    "`module load dea`\n",
    "\n",
    "\n",
    "**Background**\n",
    "\n",
    "Data from the Landsat 5,7 and 8 satellite missions are accessible through Digital Earth Australia (DEA). The code snippets in this notebook will let you retrieve and plot the Fractional Cover (FC25) data stored in DEA.\n",
    "\n",
    "\n",
    "**How to use this notebook**\n",
    "\n",
    "A basic understanding of any programming language is desirable but one doesn't have to be an expert Python programmer to manipulate the code to get and display the data.This doc applies to the following Landsat satellites, Fractional Cover bands and the WOfS dataset:\n",
    "\n",
    "- Landsat 5\n",
    "- Landsat 7\n",
    "- Landsat 8\n",
    "- PV - Photosythetic vegetation\n",
    "- NPV - Non-Photosythetic vegetation\n",
    "- BS - Bare Soil\n",
    "- UE - Unmixing Error\n",
    "- Water Observations from Space (WOFs)\n",
    "- WOfS Feature Layer (WOFL)\n",
    "\n",
    "**Bugs still to fix**\n",
    "\n",
    "- Memory errors for large (~2000 km^2) polygons\n",
    "- tidy and document the `fc_polygon_tabulation()` module. Opportunity to create additional modules to declutter.\n",
    "\n",
    "**Errors or bugs**\n",
    "\n",
    "If you find an error or bug in this notebook, please contact erin.telfer@ga.gov.au.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T05:59:41.679260Z",
     "start_time": "2019-02-04T05:59:41.658310Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from datetime import time, datetime\n",
    "import os.path\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas\n",
    "import numpy\n",
    "import xarray as xr\n",
    "import rasterio\n",
    "import rasterio.features\n",
    "import fiona\n",
    "import dask\n",
    "from dask.delayed import delayed\n",
    "from dask.distributed import LocalCluster, Client\n",
    "import tempfile\n",
    "\n",
    "import datacube\n",
    "from datacube import Datacube\n",
    "from datacube.virtual import construct, construct_from_yaml\n",
    "from datacube.ui.task_app import year_splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T05:59:47.904258Z",
     "start_time": "2019-02-04T05:59:47.865180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module datacube.ui.task_app in datacube.ui:\n",
      "\n",
      "NAME\n",
      "    datacube.ui.task_app\n",
      "\n",
      "FUNCTIONS\n",
      "    add_dataset_to_db(index, datasets)\n",
      "    \n",
      "    break_query_into_years(time_query, **kwargs)\n",
      "    \n",
      "    cell_list_to_file(filename, cell_list)\n",
      "    \n",
      "    check_existing_files(paths)\n",
      "        Check for existing files and optionally delete them.\n",
      "        \n",
      "        :param paths: sequence of path strings or path objects\n",
      "    \n",
      "    do_nothing(result)\n",
      "    \n",
      "    get_full_lineage(index, id_)\n",
      "    \n",
      "    load_config(index, app_config_file, make_config, make_tasks, *args, **kwargs)\n",
      "    \n",
      "    load_tasks(taskfile)\n",
      "    \n",
      "    pickle_stream(objs, filename)\n",
      "    \n",
      "    run_tasks(tasks, executor, run_task, process_result=None, queue_size=50)\n",
      "        :param tasks: iterable of tasks. Usually a generator to create them as required.\n",
      "        :param executor: a datacube executor, similar to `distributed.Client` or `concurrent.futures`\n",
      "        :param run_task: the function used to run a task. Expects a single argument of one of the tasks\n",
      "        :param process_result: a function to do something based on the result of a completed task. It\n",
      "                               takes a single argument, the return value from `run_task(task)`\n",
      "        :param queue_size: How large the queue of tasks should be. Will depend on how fast tasks are\n",
      "                           processed, and how much memory is available to buffer them.\n",
      "    \n",
      "    save_tasks(config, tasks, taskfile)\n",
      "        Saves the config\n",
      "        \n",
      "        :param config: dict of configuration options common to all tasks\n",
      "        :param tasks:\n",
      "        :param str taskfile: Name of output file\n",
      "        :return: Number of tasks saved to the file\n",
      "    \n",
      "    task_app(make_config, make_tasks)\n",
      "        Create a `Task App` from a function\n",
      "        \n",
      "        Decorates a function\n",
      "        :param make_config: callable(index, config, **query)\n",
      "        :param make_tasks: callable(index, config, **kwargs)\n",
      "        :return:\n",
      "    \n",
      "    unpickle_stream(filename)\n",
      "    \n",
      "    validate_cell_index(ctx, param, value)\n",
      "    \n",
      "    validate_cell_list(ctx, param, value)\n",
      "    \n",
      "    validate_year(ctx, param, value)\n",
      "    \n",
      "    wrap_task(f, *args, **kwargs)\n",
      "        Turn function `f(task, *args, **kwargs)` into `g(task)` in pickle-able fashion\n",
      "    \n",
      "    year_splitter(start, end)\n",
      "        Produces a list of time ranges based that represent each year in the range.\n",
      "        \n",
      "        `year_splitter('1992', '1993')` returns:\n",
      "        \n",
      "        ::\n",
      "            [('1992-01-01 00:00:00', '1992-12-31 23:59:59.9999999'),\n",
      "             ('1993-01-01 00:00:00', '1993-12-31 23:59:59.9999999')]\n",
      "        \n",
      "        :param str start: start year\n",
      "        :param str end: end year\n",
      "        :return Generator[tuple(str, str)]: strings representing the ranges\n",
      "\n",
      "DATA\n",
      "    absolute_import = _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0...\n",
      "\n",
      "FILE\n",
      "    /g/data/v10/public/modules/dea/20181213/lib/python3.6/site-packages/datacube/ui/task_app.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(datacube.ui.task_app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a local dask cluster\n",
    "This lets several processes work at the same time, and manage total memory usage\n",
    "\n",
    "We also get a dashboard to see how the system is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T04:10:42.744320Z",
     "start_time": "2019-02-04T04:10:38.307395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:46631\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>3</li>\n",
       "  <li><b>Cores: </b>9</li>\n",
       "  <li><b>Memory: </b>18.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:46631' processes=3 cores=9>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = LocalCluster(local_dir=tempfile.gettempdir(), \n",
    "                       n_workers=3, \n",
    "                       memory_limit=6e9)\n",
    "client = Client(cluster)\n",
    "dask.config.set(get=client.get)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T04:10:43.746410Z",
     "start_time": "2019-02-04T04:10:42.748068Z"
    }
   },
   "outputs": [],
   "source": [
    "dc = Datacube()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct virtual product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T04:10:43.756177Z",
     "start_time": "2019-02-04T04:10:43.750595Z"
    }
   },
   "outputs": [],
   "source": [
    "LS7_BROKEN_DATE = datetime(2003, 5, 31)\n",
    "is_pre_slc_failure = lambda dataset: dataset.center_time < LS7_BROKEN_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T04:10:43.767591Z",
     "start_time": "2019-02-04T04:10:43.760662Z"
    }
   },
   "outputs": [],
   "source": [
    "def wofls_fuser(dest, src):\n",
    "    where_nodata = (src & 1) == 0\n",
    "    numpy.copyto(dest, src, where=where_nodata)\n",
    "    return dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T04:10:43.785592Z",
     "start_time": "2019-02-04T04:10:43.771320Z"
    }
   },
   "outputs": [],
   "source": [
    "fc_land_only_yaml = \"\"\"\n",
    "    transform: apply_mask\n",
    "    mask_measurement_name: water\n",
    "    preserve_dtype: false\n",
    "    input:\n",
    "        juxtapose:\n",
    "          - collate:\n",
    "              - transform: apply_mask\n",
    "                mask_measurement_name: pixelquality\n",
    "                preserve_dtype: false\n",
    "                input:\n",
    "                    juxtapose:\n",
    "                      - product: ls5_fc_albers\n",
    "                        group_by: solar_day\n",
    "                        measurements: [PV, NPV, BS]\n",
    "                      - transform: make_mask\n",
    "                        input:\n",
    "                            product: ls5_pq_albers\n",
    "                            group_by: solar_day\n",
    "                            fuse_func: datacube.helpers.ga_pq_fuser\n",
    "                        flags:\n",
    "                            ga_good_pixel: true\n",
    "                        mask_measurement_name: pixelquality\n",
    "              - transform: apply_mask\n",
    "                mask_measurement_name: pixelquality\n",
    "                preserve_dtype: false\n",
    "                input:\n",
    "                    juxtapose:\n",
    "                      - product: ls7_fc_albers\n",
    "                        group_by: solar_day\n",
    "                        measurements: [PV, NPV, BS]\n",
    "                        # dataset_predicate: __main__.is_pre_slc_failure\n",
    "                      - transform: make_mask\n",
    "                        input:\n",
    "                            product: ls7_pq_albers\n",
    "                            group_by: solar_day\n",
    "                            fuse_func: datacube.helpers.ga_pq_fuser\n",
    "                        flags:\n",
    "                            ga_good_pixel: true\n",
    "                        mask_measurement_name: pixelquality\n",
    "              - transform: apply_mask\n",
    "                mask_measurement_name: pixelquality\n",
    "                preserve_dtype: false\n",
    "                input:\n",
    "                    juxtapose:\n",
    "                      - product: ls8_fc_albers\n",
    "                        group_by: solar_day\n",
    "                        measurements: [PV, NPV, BS]\n",
    "                      - transform: make_mask\n",
    "                        input:\n",
    "                            product: ls8_pq_albers\n",
    "                            group_by: solar_day\n",
    "                            fuse_func: datacube.helpers.ga_pq_fuser\n",
    "                        flags:\n",
    "                            ga_good_pixel: true\n",
    "                        mask_measurement_name: pixelquality\n",
    "          - transform: make_mask\n",
    "            input:\n",
    "                product: wofs_albers\n",
    "                group_by: solar_day\n",
    "                fuse_func: __main__.wofls_fuser\n",
    "            flags:\n",
    "                water_observed: false\n",
    "            mask_measurement_name: water\n",
    "\"\"\"\n",
    "fc_land_only = construct_from_yaml(fc_land_only_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up geometry functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T04:10:43.799401Z",
     "start_time": "2019-02-04T04:10:43.788748Z"
    }
   },
   "outputs": [],
   "source": [
    "def geometry_mask(geoms, geobox, all_touched=False, invert=False, chunks=None):\n",
    "    \"\"\"\n",
    "    Create a mask from shapes.\n",
    "\n",
    "    By default, mask is intended for use as a\n",
    "    numpy mask, where pixels that overlap shapes are False.\n",
    "    :param list[Geometry] geoms: geometries to be rasterized\n",
    "    :param datacube.utils.GeoBox geobox:\n",
    "    :param bool all_touched: If True, all pixels touched by geometries will be burned in. If\n",
    "                             false, only pixels whose center is within the polygon or that\n",
    "                             are selected by Bresenham's line algorithm will be burned in.\n",
    "    :param bool invert: If True, mask will be True for pixels that overlap shapes.\n",
    "    \"\"\"\n",
    "    data = rasterio.features.geometry_mask([geom.to_crs(geobox.crs) for geom in geoms],\n",
    "                                           out_shape=geobox.shape,\n",
    "                                           transform=geobox.affine,\n",
    "                                           all_touched=all_touched,\n",
    "                                           invert=invert)\n",
    "    if chunks is not None:\n",
    "        data = dask.array.from_array(data, chunks=tuple(chunks[d] for d in geobox.dims))\n",
    "        \n",
    "    coords = [xr.DataArray(data=coord.values, name=dim, dims=[dim], attrs={'units': coord.units}) \n",
    "              for dim, coord in geobox.coords.items()]\n",
    "    return xr.DataArray(data, coords=coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T04:10:43.811259Z",
     "start_time": "2019-02-04T04:10:43.804451Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_shapes(shape_file):\n",
    "    with fiona.open(shape_file) as shapes:\n",
    "        crs = datacube.utils.geometry.CRS(shapes.crs_wkt)\n",
    "        for shape in shapes:\n",
    "            geom = datacube.utils.geometry.Geometry(shape['geometry'], crs=crs)\n",
    "            yield geom, shape['properties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T04:10:43.868821Z",
     "start_time": "2019-02-04T04:10:43.860898Z"
    }
   },
   "outputs": [],
   "source": [
    "def fc_summary(data,mask_int):\n",
    "    fc = data[['BS', 'PV', 'NPV']].sum(dim=('x', 'y'))\n",
    "#     fc_sum = fc.to_array('variable').sum(dim='variable')\n",
    "\n",
    "    area = fc * (25 * 25 / 1_000_000)\n",
    "    area = area.rename({'BS': 'BS_area', 'PV': 'PV_area', 'NPV': 'NPV_area'})\n",
    "    for da in area.data_vars.values():\n",
    "        da.attrs['units'] = 'km2'\n",
    "\n",
    "    fc = fc / mask_int * 100 * 100\n",
    "#     fc = fc * 100 / fc_sum\n",
    "    for da in fc.data_vars.values():\n",
    "        da.attrs['units'] = '%'\n",
    "        \n",
    "    fc = fc.merge(area)\n",
    "    \n",
    "    return fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T04:10:43.879538Z",
     "start_time": "2019-02-04T04:10:43.871925Z"
    }
   },
   "outputs": [],
   "source": [
    "def keepna(a, dim=None, thresh=None):\n",
    "    if type(a) is xr.Dataset:\n",
    "        return a.apply(keepna, keep_attrs=True, dim=dim, thresh=thresh)\n",
    "    \n",
    "    keep_dim = [] if dim is None else [dim]\n",
    "    dims = [d for d in a.dims if d not in keep_dim]\n",
    "    if thresh is None:\n",
    "        keep = numpy.isfinite(a).sum(dim=dims) > 0\n",
    "    else:\n",
    "        keep = numpy.isfinite(a).sum(dim=dims) >= thresh\n",
    "    return a.where(keep, other=numpy.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T04:14:48.250624Z",
     "start_time": "2019-02-04T04:14:48.234200Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_stacked(daily_data, catchment_id, show=True):\n",
    "    if not show:\n",
    "        plt.ioff()\n",
    "        \n",
    "    fig,ax = plt.subplots(figsize=(10,5))\n",
    "    ax.stackplot(daily_data.dropna(dim='time').time.data, \n",
    "                 daily_data.dropna(dim='time').BS, \n",
    "                 daily_data.dropna(dim='time').NPV, \n",
    "                 daily_data.dropna(dim='time').PV,\n",
    "                 colors = ['tan','olive','darkolivegreen',], \n",
    "                 labels=['BS','NPV','PV',])\n",
    "    plt.legend(loc='upper center', ncol = 3)\n",
    "    plt.title(f'FC Components: Catchment ID {catchment_id}', size=12)\n",
    "    plt.ylabel('Percentage (%)', size=12) #Set Y label\n",
    "    plt.xlabel('Date', size=12) #Set X label\n",
    "    plt.savefig(f'/g/data/r78/ext547/abs/output/{catchment_id}_monthly_plot.png');\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Turn interactive back on\n",
    "    if not show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the query\n",
    "For each year and polygon query the product, apply the gemotry mask and compute the frational cover stats\n",
    "\n",
    "Using `client.compute()` lets us use the monthly results in calculating the annual results at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T06:04:24.856792Z",
     "start_time": "2019-02-04T06:04:24.716552Z"
    }
   },
   "outputs": [],
   "source": [
    "shape_file = os.path.expanduser('../input/SA_2016_threepolygons_3577.shp')\n",
    "# shape_file = os.path.expanduser('../input/SA_2016_twopolygons_3577.shp')\n",
    "shapes = list(get_shapes(shape_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T04:14:49.773452Z",
     "start_time": "2019-02-04T04:14:49.763808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2000', '2002')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_year, end_year = 2000, 2002\n",
    "time_range = (str(start_year), str(end_year))\n",
    "time_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T04:14:50.317607Z",
     "start_time": "2019-02-04T04:14:50.313618Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Use this list instead of shapes to just the big outback South Australian area\n",
    "# s2 = [(g,p) for g, p in shapes if str(p['SA2_MAIN16']) == '406021141']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T04:14:51.009149Z",
     "start_time": "2019-02-04T04:14:51.004437Z"
    }
   },
   "outputs": [],
   "source": [
    "# s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have enough resources, we can start the query and calculation of the next year's data while the previous is still being calculated. `by_slice=False` will be faster, but use more memory.\n",
    "\n",
    "For larger areas `by_slice` will need to be `True`, so that the compute cluster does not become overwhelmed.  \n",
    "\n",
    "If you get the error:\n",
    "> `distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting`\n",
    "\n",
    "then you will need to set `by_slice=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T04:14:51.941764Z",
     "start_time": "2019-02-04T04:14:51.933994Z"
    }
   },
   "outputs": [],
   "source": [
    "by_slice=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T07:06:39.304492Z",
     "start_time": "2019-02-04T06:04:28.341629Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catchment ID: 105011092, size: 56843.6928km^2, time: ('2000', '2002')\n",
      "  lazy loading ('2000-01-01 00:00:00', '2000-12-31 23:59:59.999999999')...\n",
      "    lazy loaded ('2000-01-01 00:00:00', '2000-12-31 23:59:59.999999999')\n",
      "    calculating for {'time': 12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Worker process 20229 was killed by unknown signal\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Worker process 20230 was killed by unknown signal\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Worker process 20231 was killed by unknown signal\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Worker process 1750 was killed by unknown signal\n",
      "distributed.nanny - WARNING - Restarting worker\n"
     ]
    },
    {
     "ename": "KilledWorker",
     "evalue": "('dataset-f8030b1972ad4914bf324b1b15bc60ab', 'tcp://127.0.0.1:43168')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKilledWorker\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-0e46fa2d23c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"    calculating for {dict(monthly_data.sizes)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mmonthly_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannual_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmonthly_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannual_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mby_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mmonthly_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmonthly_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mby_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/dea-env/20181015/lib/python3.6/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, collections, sync, optimize_graph, workers, allow_other_workers, resources, retries, priority, fifo_timeout, actors, **kwargs)\u001b[0m\n\u001b[1;32m   2402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2403\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2404\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2405\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2406\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/dea-env/20181015/lib/python3.6/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(self, futures, errors, maxsize, direct, asynchronous)\u001b[0m\n\u001b[1;32m   1591\u001b[0m             return self.sync(self._gather, futures, errors=errors,\n\u001b[1;32m   1592\u001b[0m                              \u001b[0mdirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1593\u001b[0;31m                              asynchronous=asynchronous)\n\u001b[0m\u001b[1;32m   1594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1595\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoroutine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/dea-env/20181015/lib/python3.6/site-packages/distributed/client.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    645\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/dea-env/20181015/lib/python3.6/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/dea-env/20181015/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/dea-env/20181015/lib/python3.6/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/dea-env/20181015/lib/python3.6/site-packages/tornado/gen.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m                         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhad_exception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/dea-env/20181015/lib/python3.6/site-packages/tornado/concurrent.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m                 \u001b[0mraise_exc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/dea-env/20181015/lib/python3.6/site-packages/tornado/util.py\u001b[0m in \u001b[0;36mraise_exc_info\u001b[0;34m(exc_info)\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/dea-env/20181015/lib/python3.6/site-packages/tornado/gen.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mexc_info\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m                             \u001b[0myielded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m                         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m                             \u001b[0;31m# Break up a reference to itself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/dea-env/20181015/lib/python3.6/site-packages/distributed/client.py\u001b[0m in \u001b[0;36m_gather\u001b[0;34m(self, futures, errors, direct, local_worker)\u001b[0m\n\u001b[1;32m   1467\u001b[0m                             six.reraise(type(exception),\n\u001b[1;32m   1468\u001b[0m                                         \u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1469\u001b[0;31m                                         traceback)\n\u001b[0m\u001b[1;32m   1470\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'skip'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m                         \u001b[0mbad_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/dea-env/20181015/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKilledWorker\u001b[0m: ('dataset-f8030b1972ad4914bf324b1b15bc60ab', 'tcp://127.0.0.1:43168')"
     ]
    }
   ],
   "source": [
    "for geometry, properties in shapes:\n",
    "    catchment_id = str(properties['SA2_MAIN16'])\n",
    "    print(f\"Catchment ID: {catchment_id}, size: {properties['AREASQKM16']}km^2, time: {time_range}\")\n",
    "          \n",
    "    monthly_values = []\n",
    "    annual_values = []\n",
    "    mask = None\n",
    "          \n",
    "    for sub_time_range in year_splitter(time_range[0], time_range[-1]):\n",
    "        print(f'  lazy loading {sub_time_range}...')  \n",
    "        data = fc_land_only.load(dc, dask_chunks={'time': 1, 'y': 4000, 'x': 4000}, \n",
    "                                 time=sub_time_range, \n",
    "                                 geopolygon=geometry)\n",
    "        print(f'    lazy loaded {sub_time_range}')\n",
    "\n",
    "        if mask is None:\n",
    "          mask = geometry_mask([geometry], data.geobox, invert=True, chunks=data.chunks)\n",
    "          mask_int = int(mask.sum())\n",
    "        data = data.where(mask)\n",
    "\n",
    "        data = data.resample(time='1MS').mean(dim='time', skipna=True)\n",
    "        data = keepna(data, dim='time', thresh=0.9*int(mask.sum()))\n",
    "\n",
    "        monthly_data = fc_summary(data, mask_int)\n",
    "#         annual_data = monthly_data.resample(time='1YS').mean(dim='time', skipna=True)\n",
    "\n",
    "        print(f\"    calculating for {dict(monthly_data.sizes)}\")\n",
    "        monthly_data, annual_data = client.compute([monthly_data, annual_data], sync=by_slice)\n",
    "        monthly_data = client.compute([monthly_data], sync=by_slice)\n",
    "\n",
    "        print(\"    compute submitted\")\n",
    "          \n",
    "        monthly_values.append(monthly_data)\n",
    "        annual_values.append(annual_data)\n",
    "    \n",
    "    if not by_slice:\n",
    "        print(\"  all years queried, hard load data\")\n",
    "        monthly_values = client.gather(monthly_values)\n",
    "        annual_values = client.gather(annual_values)\n",
    "\n",
    "    monthly_values = xr.concat(monthly_values, dim='time').dropna(dim='time')\n",
    "    plot_stacked(monthly_values, catchment_id, show=False)\n",
    "          \n",
    "    annual_values = xr.concat(annual_values, dim='time').dropna(dim='time')\n",
    "          \n",
    "#     print(\"  all data loaded, save to csv\")\n",
    "#     monthly_values.to_dataframe().to_csv(f\"/g/data/r78/ext547/abs/output/{catchment_id}_monthly.csv\")\n",
    "#     annual_values.to_dataframe().to_csv(f\"/g/data/r78/ext547/abs/output/{catchment_id}_annual.csv\")\n",
    "          \n",
    "    print(f\"  Catchment {catchment_id} done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:20181015]",
   "language": "python",
   "name": "conda-env-20181015-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
