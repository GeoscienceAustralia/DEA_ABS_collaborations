{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabulation of Fractional Cover data within tiled shapefile polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T04:13:20.577632Z",
     "start_time": "2019-02-04T04:13:20.554372Z"
    }
   },
   "source": [
    "**What does this notebook do?**\n",
    "\n",
    "This notebook is a pilot collaboration between Geoscience Australia and Australian Bureau of Statistics. The purpose of the notebook is to use a shapefile of SA2 boundaries to load the Fractional Cover (FC) dataset, complete zonal statistics and tabulate the results.\n",
    "\n",
    "This workflow has been created to run large SA2 within memory on the VDI and uses pre-tiled SA2 polygons as an input. Once the monthly tabulation script is complete the workflow reads the tabulated results and calculates annual results and quality metrics. \n",
    "\n",
    "**Requirements**\n",
    "\n",
    "A shapefile that contains **tiled** SA2 polygons. The Intersect tool in ArcGIS was used to break the large (>20 000 km2) SA2 into Australian Albers 100 km by 100 km tiles.\n",
    "\n",
    "You need to run the following commands from the command line prior to launching jupyter notebooks from the same terminal so that the required libraries and paths are set:\n",
    "\n",
    "`module use /g/data/v10/public/modules/modulefiles`\n",
    "\n",
    "`module load dea/20181213`\n",
    "\n",
    "\n",
    "**Background**\n",
    "\n",
    "Data from the Landsat 5,7 and 8 satellite missions are accessible through Digital Earth Australia (DEA). The code snippets in this notebook will let you retrieve and tabulate the FC data stored in DEA.\n",
    "\n",
    "\n",
    "**How to use this notebook**\n",
    "\n",
    "A basic understanding of any programming language is desirable but one doesn't have to be an expert Python programmer to manipulate the code to get and display the data.This doc applies to the following Landsat satellites, Fractional Cover bands and the WOfS dataset:\n",
    "\n",
    "- Landsat 5\n",
    "- Landsat 7\n",
    "- Landsat 8\n",
    "- PV - Photosythetic vegetation\n",
    "- NPV - Non-Photosythetic vegetation\n",
    "- BS - Bare Soil\n",
    "- UE - Unmixing Error\n",
    "- Water Observations from Space (WOFs)\n",
    "- WOfS Feature Layer (WOFL)\n",
    "\n",
    "**Bugs still to fix**\n",
    "-  NA\n",
    "\n",
    "**Errors or bugs**\n",
    "\n",
    "If you find an error or bug in this notebook, please contact erin.telfer@ga.gov.au.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T07:46:21.340855Z",
     "start_time": "2019-06-11T07:46:21.314904Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from datetime import time, datetime\n",
    "import os.path\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import csv\n",
    "import xarray as xr\n",
    "import rasterio\n",
    "import rasterio.features\n",
    "import fiona\n",
    "from datetime import datetime\n",
    "import dask\n",
    "from dask.delayed import delayed\n",
    "from dask.distributed import LocalCluster, Client\n",
    "import tempfile\n",
    "\n",
    "import datacube\n",
    "from datacube import Datacube\n",
    "from datacube.virtual import construct, construct_from_yaml\n",
    "from datacube.ui.task_app import year_splitter\n",
    "from datacube.utils.geometry import CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T10:59:23.645505Z",
     "start_time": "2019-06-11T10:59:23.636351Z"
    }
   },
   "outputs": [],
   "source": [
    "#input years range of interest\n",
    "start_year = 2015\n",
    "end_year = 2017\n",
    "\n",
    "#input batch details\n",
    "initials = 'ET'\n",
    "batch_sa2_size = 'over20000_702051066'\n",
    "run_date = '11June19'\n",
    "run_notes = 'rerun of the last batch to include SA2 of Gulf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. USER INPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T05:21:00.322146Z",
     "start_time": "2019-05-30T05:21:00.316563Z"
    }
   },
   "source": [
    "## 3. Set directory and shapefile details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T10:59:26.612021Z",
     "start_time": "2019-06-11T10:59:26.604196Z"
    }
   },
   "outputs": [],
   "source": [
    "#Set folder location and shapefile name\n",
    "shapefile_path = '/g/data/r78/ext547/abs/input/SA_2016_clipped_albers_3577.shp'\n",
    "#Set output folder\n",
    "output_path = '/g/data/r78/ext547/abs/output/'\n",
    "#Set name for output csv\n",
    "name_of_output_file =f'tabulate_FC_{run_date}_{batch_sa2_size}_{start_year}_{end_year}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T10:59:27.640640Z",
     "start_time": "2019-06-11T10:59:27.631272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2015', '2017')\n"
     ]
    }
   ],
   "source": [
    "#Years of interest are saved in expected format\n",
    "time_range = (str(start_year), str(end_year))\n",
    "print(time_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Set up a local dask cluster\n",
    "Some calculations take more memory than is available on a system.  By breaking the data up into chunks, we can chain a sequence of operations together, and work on the data a small piece at a time.\n",
    "\n",
    "This lets several processes work at the same time, and manage total memory usage for the calculations.\n",
    "\n",
    "In more advanced setups, we can distribute the work across multiple computers, using all of their memory and CPU power.\n",
    "\n",
    "* We set `n_workers` to be the number of worker applications we want to run in the background, doing the processing of the chunk-based steps we have chained together.\n",
    "* The `mem_per_worker` setting defines how much memory at most is available to each of the workers.\n",
    "* `chunk_size` sets the width and height of the chunk in pixels of the size will break up the data into.\n",
    "\n",
    "VDI has 8 CPUs available, and a total of 32GB of memory, but you will typically be sharing those with several (2-10) other users.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T10:59:29.069892Z",
     "start_time": "2019-06-11T10:59:29.058634Z"
    }
   },
   "outputs": [],
   "source": [
    "#Set up dask cluster\n",
    "n_workers = 7\n",
    "threads_per_worker=1\n",
    "mem_per_worker = 8e9  # 8e9 is 8GB (8,000,000,000 bytes)\n",
    "\n",
    "chunk_size = {'time': 1, 'x': 2000, 'y': 2000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T10:59:53.661889Z",
     "start_time": "2019-06-11T10:59:50.850305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:33090\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:33612/status' target='_blank'>http://127.0.0.1:33612/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>7</li>\n",
       "  <li><b>Cores: </b>7</li>\n",
       "  <li><b>Memory: </b>56.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:33090' processes=7 cores=7>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = LocalCluster(local_dir=tempfile.gettempdir(), \n",
    "                       n_workers=n_workers, \n",
    "                       threads_per_worker=threads_per_worker,\n",
    "                       memory_limit=mem_per_worker)\n",
    "client = Client(cluster)\n",
    "dask.config.set(get=client.get)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also get a dashboard to see how the system is running, by clicking the link above after the cell has been run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Connect to the Datacube "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T10:59:53.741125Z",
     "start_time": "2019-06-11T10:59:53.665924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell finished at 2019-06-11 20:59:53\n"
     ]
    }
   ],
   "source": [
    "dc = Datacube()\n",
    "print(f\"Cell finished at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Construct the virtual product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T10:59:53.753324Z",
     "start_time": "2019-06-11T10:59:53.746414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell finished at 2019-06-11 20:59:53\n"
     ]
    }
   ],
   "source": [
    "#Remove Landsat 7 scenes with the Scan Line Correction (SLC) missing data\n",
    "LS7_BROKEN_DATE = datetime(2003, 5, 31)\n",
    "is_pre_slc_failure = lambda dataset: dataset.center_time < LS7_BROKEN_DATE\n",
    "print(f\"Cell finished at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T10:59:53.774765Z",
     "start_time": "2019-06-11T10:59:53.757138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell finished at 2019-06-11 20:59:53\n"
     ]
    }
   ],
   "source": [
    "#Create function to ensure wofls in correct format\n",
    "def wofls_fuser(dest, src):\n",
    "    where_nodata = (src & 1) == 0\n",
    "    numpy.copyto(dest, src, where=where_nodata)\n",
    "    return dest\n",
    "print(f\"Cell finished at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T10:59:53.873338Z",
     "start_time": "2019-06-11T10:59:53.780763Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create virtual product so that datacube data can be loaded effectively within memory\n",
    "fc_and_water_yaml = \"\"\"\n",
    "        juxtapose:\n",
    "          - collate:\n",
    "              - transform: apply_mask\n",
    "                mask_measurement_name: pixelquality\n",
    "                preserve_dtype: false\n",
    "                input:\n",
    "                    juxtapose:\n",
    "                      - product: ls5_fc_albers\n",
    "                        group_by: solar_day\n",
    "                        measurements: [PV, NPV, BS]\n",
    "                      - transform: make_mask\n",
    "                        input:\n",
    "                            product: ls5_pq_albers\n",
    "                            group_by: solar_day\n",
    "                            fuse_func: datacube.helpers.ga_pq_fuser\n",
    "                        flags:\n",
    "                            ga_good_pixel: true\n",
    "                        mask_measurement_name: pixelquality\n",
    "              - transform: apply_mask\n",
    "                mask_measurement_name: pixelquality\n",
    "                preserve_dtype: false\n",
    "                input:\n",
    "                    juxtapose:\n",
    "                      - product: ls7_fc_albers\n",
    "                        group_by: solar_day\n",
    "                        measurements: [PV, NPV, BS]\n",
    "                        # dataset_predicate: __main__.is_pre_slc_failure\n",
    "                      - transform: make_mask\n",
    "                        input:\n",
    "                            product: ls7_pq_albers\n",
    "                            group_by: solar_day\n",
    "                            fuse_func: datacube.helpers.ga_pq_fuser\n",
    "                        flags:\n",
    "                            ga_good_pixel: true\n",
    "                        mask_measurement_name: pixelquality\n",
    "              - transform: apply_mask\n",
    "                mask_measurement_name: pixelquality\n",
    "                preserve_dtype: false\n",
    "                input:\n",
    "                    juxtapose:\n",
    "                      - product: ls8_fc_albers\n",
    "                        group_by: solar_day\n",
    "                        measurements: [PV, NPV, BS]\n",
    "                      - transform: make_mask\n",
    "                        input:\n",
    "                            product: ls8_pq_albers\n",
    "                            group_by: solar_day\n",
    "                            fuse_func: datacube.helpers.ga_pq_fuser\n",
    "                        flags:\n",
    "                            ga_good_pixel: true\n",
    "                        mask_measurement_name: pixelquality\n",
    "          - transform: make_mask\n",
    "            input:\n",
    "                product: wofs_albers\n",
    "                group_by: solar_day\n",
    "                fuse_func: __main__.wofls_fuser\n",
    "            flags:\n",
    "                wet: true\n",
    "            mask_measurement_name: water\n",
    "\"\"\"\n",
    "fc_and_water = construct_from_yaml(fc_and_water_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Set up functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T10:59:53.891970Z",
     "start_time": "2019-06-11T10:59:53.876956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell finished at 2019-06-11 20:59:53\n"
     ]
    }
   ],
   "source": [
    "def geometry_mask(geoms, geobox, all_touched=False, invert=False, chunks=None):\n",
    "    \"\"\"\n",
    "    Create a mask from shapes.\n",
    "\n",
    "    By default, mask is intended for use as a\n",
    "    numpy mask, where pixels that overlap shapes are False.\n",
    "    :param list[Geometry] geoms: geometries to be rasterized\n",
    "    :param datacube.utils.GeoBox geobox:\n",
    "    :param bool all_touched: If True, all pixels touched by geometries will be burned in. If\n",
    "                             false, only pixels whose center is within the polygon or that\n",
    "                             are selected by Bresenham's line algorithm will be burned in.\n",
    "    :param bool invert: If True, mask will be True for pixels that overlap shapes.\n",
    "    \"\"\"\n",
    "    data = rasterio.features.geometry_mask([geom.to_crs(geobox.crs) for geom in geoms],\n",
    "                                           out_shape=geobox.shape,\n",
    "                                           transform=geobox.affine,\n",
    "                                           all_touched=all_touched,\n",
    "                                           invert=invert)\n",
    "    if chunks is not None:\n",
    "        data = dask.array.from_array(data, chunks=tuple(chunks[d] for d in geobox.dims))\n",
    "        \n",
    "    coords = [xr.DataArray(data=coord.values, name=dim, dims=[dim], attrs={'units': coord.units}) \n",
    "              for dim, coord in geobox.coords.items()]\n",
    "    return xr.DataArray(data, coords=coords)\n",
    "print(f\"Cell finished at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T10:59:53.906804Z",
     "start_time": "2019-06-11T10:59:53.898923Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_shapes(shape_file):\n",
    "    \"\"\"\n",
    "    Extract spatial inforamtion from polygons within shapefile\n",
    "    \"\"\"\n",
    "    with fiona.open(shape_file) as shapes:\n",
    "        crs = datacube.utils.geometry.CRS(shapes.crs_wkt)\n",
    "        for shape in shapes:\n",
    "            if shape['geometry'] is None:\n",
    "                continue\n",
    "            geom = datacube.utils.geometry.Geometry(shape['geometry'], crs=crs)\n",
    "            geom = geom.to_crs(CRS('EPSG:3577'))\n",
    "            yield geom, shape['properties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T10:59:53.929990Z",
     "start_time": "2019-06-11T10:59:53.911155Z"
    }
   },
   "outputs": [],
   "source": [
    "def fc_and_water_summary(data, mask_int):\n",
    "    \"\"\"\n",
    "    Calculate the percentage and the area of each FC component, \n",
    "    water, and unclassified data within each SA2 boundary. \n",
    "    \"\"\"\n",
    "    # Where there is water, set the FC bands to 0%\n",
    "    valid_data = numpy.isfinite(data['BS'])\n",
    "    fc = data[['PV', 'NPV', 'BS']].where(data.water==0, other=0)\n",
    "    fc['water'] = data.water.where(valid_data) * numpy.float32(100)\n",
    "    fc = fc.apply(lambda data_array: data_array.clip(0, 100).where(valid_data))\n",
    "\n",
    "    has_data = valid_data.groupby(valid_data.time.astype('datetime64[M]'), squeeze=False).sum(dim='time', skipna=False)\n",
    "    has_data = has_data.sum(dim=['x','y'], skipna=True) #/ (mask_int / 100)\n",
    "\n",
    "    # Flatten to a monthly mean\n",
    "    fc = fc.groupby(fc.time.astype('datetime64[M]'), squeeze=False).mean(dim='time', skipna=True)\n",
    "    # Calculate percentage of cover based on area of mask\n",
    "    percentage = fc.sum(dim=['x','y']) * (100 / mask_int)\n",
    "    for da in percentage.data_vars.values():\n",
    "        da.attrs['units'] = '%'\n",
    "    fc['mask_int'] = mask_int         \n",
    "    #calculate area of fc components\n",
    "    pixel_area_in_metres2 = 25 * 25\n",
    "    m2_to_km2 = (1 / 1_000_000)\n",
    "    percent_to_fraction = (1 / 100)\n",
    "    area = (fc * (pixel_area_in_metres2 * m2_to_km2 * percent_to_fraction)).sum(dim=['x','y'])\n",
    "    area = area.rename({'BS': 'BS_area', \n",
    "                        'PV': 'PV_area', \n",
    "                        'NPV': 'NPV_area', \n",
    "                        'water': 'water_area',\n",
    "                        'mask_int':'mask_area',})\n",
    "\n",
    "    for da in area.data_vars.values():\n",
    "        da.attrs['units'] = 'km^2'\n",
    "    fc = percentage.merge(area)\n",
    "    fc['average_data_count'] = has_data\n",
    "    fc['mask_int'] = mask_int\n",
    "\n",
    "    return fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T10:59:53.941784Z",
     "start_time": "2019-06-11T10:59:53.933198Z"
    }
   },
   "outputs": [],
   "source": [
    "def month_splitter(start_year, end_year_inclusive):\n",
    "    \"\"\" \n",
    "    Split specified years into months \n",
    "    \"\"\"\n",
    "    yield from (str(p) for p in pd.period_range(start=pd.Period(start_year).start_time, \n",
    "                               end=pd.Period(end_year_inclusive).end_time, \n",
    "                               freq='M'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T10:59:53.955878Z",
     "start_time": "2019-06-11T10:59:53.946431Z"
    }
   },
   "outputs": [],
   "source": [
    "def output_csv(input_ds, sa2_id, sa2_name, sa2_size, albers_id,name_of_output_file, monthly_or_annual='frequency'):\n",
    "    \"\"\"\n",
    "    Save tabulated data into a csv\n",
    "    \"\"\"\n",
    "    input_ds = input_ds.to_dataframe()\n",
    "    input_ds.insert(0,'SA2_id', sa2_id)\n",
    "    input_ds.insert(1,'SA2_name', sa2_name)\n",
    "    input_ds.insert(2,'albers_id', albers_id)\n",
    "    input_ds.insert(3,'SA2_size', sa2_size)\n",
    "    input_ds.to_csv(f\"{output_path}/{name_of_output_file}_{monthly_or_annual}.csv\",mode='a',header=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Set up the query\n",
    "For each year and polygon query the product, apply the geometry mask and compute the fractional cover stats\n",
    "\n",
    "Using `client.compute()` lets us use the monthly results in calculating the annual results at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T11:00:04.685986Z",
     "start_time": "2019-06-11T11:00:01.803384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "#Obtain spatial information from shapefile\n",
    "shape_file = os.path.expanduser(f'{shapefile_path}')\n",
    "shapes = list(get_shapes(shape_file))\n",
    "\n",
    "#Specify a particular SA2 boundary, if required, otherwise keep hashed out\n",
    "shapes = [(g,p) for g, p in shapes if str(p['SA2_MAIN16']) == '702051066']\n",
    "# shapes = [(g,p) for g, p in shapes if int(p['AREASQKM16']) < 25_000]\n",
    "\n",
    "print(len(shapes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have enough resources, we can start the query and calculation of the next year's data while the previous is still being calculated. `by_slice=False` will be faster, but use more memory.\n",
    "\n",
    "For larger areas `by_slice` will need to be `True`, so that the compute cluster does not become overwhelmed.  \n",
    "\n",
    "If you get the error:\n",
    "> `distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting`\n",
    "\n",
    "then you will need to set `by_slice=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T11:00:04.696000Z",
     "start_time": "2019-06-11T11:00:04.690513Z"
    }
   },
   "outputs": [],
   "source": [
    "by_slice=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T11:00:04.775729Z",
     "start_time": "2019-06-11T11:00:04.747558Z"
    }
   },
   "outputs": [],
   "source": [
    "monthly_values = None\n",
    "def process_area(geometry, sa2_id, sa2_name, sa2_size, albers_id, name_of_output_file, time_range):\n",
    "    \"\"\" loop through each month within the time range and load fc data with virtual products, \n",
    "    mask to tiled SA2 boundary, tabulate monthly results and append to output.\n",
    "    \"\"\"\n",
    "    monthly_values = []\n",
    "    annual_values = []\n",
    "    mask = None\n",
    "    \n",
    "    # Set geometry values to use Virtual Products, use this instead of `geopolygon=geometry` \n",
    "    search_terms = {\n",
    "        'x': (geometry.envelope.left, geometry.envelope.right),\n",
    "        'y': (geometry.envelope.top, geometry.envelope.bottom),\n",
    "        'crs': str(geometry.crs), }  \n",
    "\n",
    "    #loop through months within the date range\n",
    "    for sub_time_range in month_splitter(time_range[0], time_range[-1]):\n",
    "        print(sub_time_range)\n",
    "        \n",
    "        #load fc data using Virtual Products\n",
    "        try:\n",
    "            data = fc_and_water.load(dc, dask_chunks=chunk_size, \n",
    "                                     time=sub_time_range, \n",
    "                                     **search_terms)\n",
    "        #if there is no data within this month, skip the load, and continue a load with the next month\n",
    "        except ValueError:\n",
    "            print(f'    No data for {sub_time_range} , skipping...')\n",
    "            continue\n",
    "        \n",
    "        #mask data with tiled SA2 polygon to remove data that is outside of the polygon\n",
    "        if mask is None:\n",
    "            mask = geometry_mask([geometry], data.geobox, invert=True, chunks=data.chunks)\n",
    "            mask_int = mask * 1 #turn variable into an int\n",
    "            mask_int = mask_int.sum() * 100 #create a varaible that counts the number of pixels within the tiles SA2 polygon\n",
    "        data = data.where(mask) \n",
    "        \n",
    "        #use function to tabulate fc components\n",
    "        monthly_data = fc_and_water_summary(data, mask_int)\n",
    "        #load data into memory from dask\n",
    "        monthly_data = client.compute(monthly_data, sync=by_slice)\n",
    "        #append monthly results into a list that contains the values for all other months \n",
    "        monthly_values.append(monthly_data)\n",
    "        \n",
    "    if not by_slice:\n",
    "        print(\"  all years queried, hard load data\")\n",
    "        monthly_values = client.gather(monthly_values)\n",
    "    #concatenate the monthly results together into an xarray    \n",
    "    monthly_values = xr.concat(monthly_values, dim='time')\n",
    "    \n",
    "    #append results to a csv\n",
    "    print(\"All data loaded, save to csv\")\n",
    "    output_csv(monthly_values, sa2_id, sa2_name, sa2_size,albers_id, name_of_output_file, monthly_or_annual='monthly')\n",
    "       \n",
    "    print(f\"SA2 {sa2_id} done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Create empty CSVs to save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T11:00:24.000646Z",
     "start_time": "2019-06-11T11:00:23.970006Z"
    }
   },
   "outputs": [],
   "source": [
    "#Specified headings\n",
    "header = ['DATE','SA2_MAIN16', 'SA2_NAME16', 'ALBERS3577_ID', 'AREASQKM16',\n",
    "          'PV_PERCENTAGE','NPV_PERCENTAGE','BS_PERCENTAGE','WOFL_PERCENTAGE',\n",
    "          'PV_AREA_SQKM_ALBERS3577','NPV_AREA_SQKM_ALBERS3577',\n",
    "          'BS_AREA_SQKM_ALBERS3577','WOFL_AREA_SQKM_ALBERS3577','FC_AREA_SQKM_ALBERS3577', \n",
    "          'AVERAGE_OBSERVATION_COUNT','SA2_TILE_PIXEL_COUNT']\n",
    "\n",
    "error_header = ['','RUN_NAME','SA2_MAIN16','DATE_RANGE','ERROR_MESSAGE']\n",
    "\n",
    "#Create an empty CSV for monthly results    \n",
    "with open(f\"{output_path}/{name_of_output_file}_monthly.csv\",\"w\") as outcsv:\n",
    "    writer = csv.writer(outcsv)\n",
    "    writer.writerow(header)\n",
    "\n",
    "#Create csv to save error output\n",
    "with open(f\"{output_path}/{name_of_output_file}_error_log.csv\",\"w\") as outcsv: \n",
    "    writer = csv.writer(outcsv)\n",
    "    writer.writerow(error_header)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Run tabulation script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T13:51:29.505197Z",
     "start_time": "2019-06-11T11:00:28.551951Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA2 ID: 702051066, Albers tile: 2,-15, SA2 size: 92275.0274km^2, time: ('2015', '2017')\n",
      "2015-01\n",
      "2015-02\n",
      "2015-03\n",
      "2015-04\n",
      "2015-05\n",
      "2015-06\n",
      "2015-07\n",
      "2015-08\n",
      "2015-09\n",
      "2015-10\n",
      "2015-11\n",
      "2015-12\n",
      "2016-01\n",
      "2016-02\n",
      "2016-03\n",
      "2016-04\n",
      "2016-05\n",
      "2016-06\n",
      "2016-07\n",
      "2016-08\n",
      "2016-09\n",
      "2016-10\n",
      "2016-11\n",
      "2016-12\n",
      "2017-01\n",
      "2017-02\n",
      "2017-03\n",
      "2017-04\n",
      "2017-05\n",
      "2017-06\n",
      "2017-07\n",
      "2017-08\n",
      "2017-09\n",
      "2017-10\n",
      "2017-11\n",
      "2017-12\n",
      "All data loaded, save to csv\n",
      "SA2 702051066 done\n",
      "SA2 ID: 702051066, Albers tile: 3,-15, SA2 size: 92275.0274km^2, time: ('2015', '2017')\n",
      "2015-01\n",
      "2015-02\n",
      "2015-03\n",
      "2015-04\n",
      "2015-05\n",
      "2015-06\n",
      "2015-07\n",
      "2015-08\n",
      "2015-09\n",
      "2015-10\n",
      "2015-11\n",
      "2015-12\n",
      "2016-01\n",
      "2016-02\n",
      "2016-03\n",
      "2016-04\n",
      "2016-05\n",
      "2016-06\n",
      "2016-07\n",
      "2016-08\n",
      "2016-09\n",
      "2016-10\n",
      "2016-11\n",
      "2016-12\n",
      "2017-01\n",
      "2017-02\n",
      "2017-03\n",
      "2017-04\n",
      "2017-05\n",
      "2017-06\n",
      "2017-07\n",
      "2017-08\n",
      "2017-09\n",
      "2017-10\n",
      "2017-11\n",
      "2017-12\n",
      "All data loaded, save to csv\n",
      "SA2 702051066 done\n",
      "SA2 ID: 702051066, Albers tile: 4,-15, SA2 size: 92275.0274km^2, time: ('2015', '2017')\n",
      "2015-01\n",
      "2015-02\n",
      "2015-03\n",
      "2015-04\n",
      "2015-05\n",
      "2015-06\n",
      "2015-07\n",
      "2015-08\n",
      "2015-09\n",
      "2015-10\n",
      "2015-11\n",
      "2015-12\n",
      "2016-01\n",
      "2016-02\n",
      "2016-03\n",
      "2016-04\n",
      "2016-05\n",
      "2016-06\n",
      "2016-07\n",
      "2016-08\n",
      "2016-09\n",
      "2016-10\n",
      "2016-11\n",
      "2016-12\n",
      "2017-01\n",
      "2017-02\n",
      "2017-03\n",
      "2017-04\n",
      "2017-05\n",
      "2017-06\n",
      "2017-07\n",
      "2017-08\n",
      "2017-09\n",
      "2017-10\n",
      "2017-11\n",
      "2017-12\n",
      "All data loaded, save to csv\n",
      "SA2 702051066 done\n",
      "SA2 ID: 702051066, Albers tile: 2,-16, SA2 size: 92275.0274km^2, time: ('2015', '2017')\n",
      "2015-01\n",
      "2015-02\n",
      "2015-03\n",
      "2015-04\n",
      "2015-05\n",
      "2015-06\n",
      "2015-07\n",
      "2015-08\n",
      "2015-09\n",
      "2015-10\n",
      "2015-11\n",
      "2015-12\n",
      "2016-01\n",
      "2016-02\n",
      "2016-03\n",
      "2016-04\n",
      "2016-05\n",
      "2016-06\n",
      "2016-07\n",
      "2016-08\n",
      "2016-09\n",
      "2016-10\n",
      "2016-11\n",
      "2016-12\n",
      "2017-01\n",
      "2017-02\n",
      "2017-03\n",
      "2017-04\n",
      "2017-05\n",
      "2017-06\n",
      "2017-07\n",
      "2017-08\n",
      "2017-09\n",
      "2017-10\n",
      "2017-11\n",
      "2017-12\n",
      "All data loaded, save to csv\n",
      "SA2 702051066 done\n",
      "SA2 ID: 702051066, Albers tile: 3,-16, SA2 size: 92275.0274km^2, time: ('2015', '2017')\n",
      "2015-01\n",
      "2015-02\n",
      "2015-03\n",
      "2015-04\n",
      "2015-05\n",
      "2015-06\n",
      "2015-07\n",
      "2015-08\n",
      "2015-09\n",
      "2015-10\n",
      "2015-11\n",
      "2015-12\n",
      "2016-01\n",
      "2016-02\n",
      "2016-03\n",
      "2016-04\n",
      "2016-05\n",
      "2016-06\n",
      "2016-07\n",
      "2016-08\n",
      "2016-09\n",
      "2016-10\n",
      "2016-11\n",
      "2016-12\n",
      "2017-01\n",
      "2017-02\n",
      "2017-03\n",
      "2017-04\n",
      "2017-05\n",
      "2017-06\n",
      "2017-07\n",
      "2017-08\n",
      "2017-09\n",
      "2017-10\n",
      "2017-11\n",
      "2017-12\n",
      "All data loaded, save to csv\n",
      "SA2 702051066 done\n",
      "SA2 ID: 702051066, Albers tile: 4,-16, SA2 size: 92275.0274km^2, time: ('2015', '2017')\n",
      "2015-01\n",
      "2015-02\n",
      "2015-03\n",
      "2015-04\n",
      "2015-05\n",
      "2015-06\n",
      "2015-07\n",
      "2015-08\n",
      "2015-09\n",
      "2015-10\n",
      "2015-11\n",
      "2015-12\n",
      "2016-01\n",
      "2016-02\n",
      "2016-03\n",
      "2016-04\n",
      "2016-05\n",
      "2016-06\n",
      "2016-07\n",
      "2016-08\n",
      "2016-09\n",
      "2016-10\n",
      "2016-11\n",
      "2016-12\n",
      "2017-01\n",
      "2017-02\n",
      "2017-03\n",
      "2017-04\n",
      "2017-05\n",
      "2017-06\n",
      "2017-07\n",
      "2017-08\n",
      "2017-09\n",
      "2017-10\n",
      "2017-11\n",
      "2017-12\n",
      "All data loaded, save to csv\n",
      "SA2 702051066 done\n",
      "SA2 ID: 702051066, Albers tile: 2,-17, SA2 size: 92275.0274km^2, time: ('2015', '2017')\n",
      "2015-01\n",
      "2015-02\n",
      "2015-03\n",
      "2015-04\n",
      "2015-05\n",
      "2015-06\n",
      "2015-07\n",
      "2015-08\n",
      "2015-09\n",
      "2015-10\n",
      "2015-11\n",
      "2015-12\n",
      "2016-01\n",
      "2016-02\n",
      "2016-03\n",
      "2016-04\n",
      "2016-05\n",
      "2016-06\n",
      "2016-07\n",
      "2016-08\n",
      "2016-09\n",
      "2016-10\n",
      "2016-11\n",
      "2016-12\n",
      "2017-01\n",
      "2017-02\n",
      "2017-03\n",
      "2017-04\n",
      "2017-05\n",
      "2017-06\n",
      "2017-07\n",
      "2017-08\n",
      "2017-09\n",
      "2017-10\n",
      "2017-11\n",
      "2017-12\n",
      "All data loaded, save to csv\n",
      "SA2 702051066 done\n",
      "SA2 ID: 702051066, Albers tile: 3,-17, SA2 size: 92275.0274km^2, time: ('2015', '2017')\n",
      "2015-01\n",
      "2015-02\n",
      "2015-03\n",
      "2015-04\n",
      "2015-05\n",
      "2015-06\n",
      "2015-07\n",
      "2015-08\n",
      "2015-09\n",
      "2015-10\n",
      "2015-11\n",
      "2015-12\n",
      "2016-01\n",
      "2016-02\n",
      "2016-03\n",
      "2016-04\n",
      "2016-05\n",
      "2016-06\n",
      "2016-07\n",
      "2016-08\n",
      "2016-09\n",
      "2016-10\n",
      "2016-11\n",
      "2016-12\n",
      "2017-01\n",
      "2017-02\n",
      "2017-03\n",
      "2017-04\n",
      "2017-05\n",
      "2017-06\n",
      "2017-07\n",
      "2017-08\n",
      "2017-09\n",
      "2017-10\n",
      "2017-11\n",
      "2017-12\n",
      "All data loaded, save to csv\n",
      "SA2 702051066 done\n",
      "SA2 ID: 702051066, Albers tile: 4,-17, SA2 size: 92275.0274km^2, time: ('2015', '2017')\n",
      "2015-01\n",
      "2015-02\n",
      "2015-03\n",
      "2015-04\n",
      "2015-05\n",
      "2015-06\n",
      "2015-07\n",
      "2015-08\n",
      "2015-09\n",
      "2015-10\n",
      "2015-11\n",
      "2015-12\n",
      "2016-01\n",
      "2016-02\n",
      "2016-03\n",
      "2016-04\n",
      "2016-05\n",
      "2016-06\n",
      "2016-07\n",
      "2016-08\n",
      "2016-09\n",
      "2016-10\n",
      "2016-11\n",
      "2016-12\n",
      "2017-01\n",
      "2017-02\n",
      "2017-03\n",
      "2017-04\n",
      "2017-05\n",
      "2017-06\n",
      "2017-07\n",
      "2017-08\n",
      "2017-09\n",
      "2017-10\n",
      "2017-11\n",
      "2017-12\n",
      "All data loaded, save to csv\n",
      "SA2 702051066 done\n",
      "SA2 ID: 702051066, Albers tile: 5,-17, SA2 size: 92275.0274km^2, time: ('2015', '2017')\n",
      "2015-01\n",
      "2015-02\n",
      "2015-03\n",
      "2015-04\n",
      "2015-05\n",
      "2015-06\n",
      "2015-07\n",
      "2015-08\n",
      "2015-09\n",
      "2015-10\n",
      "2015-11\n",
      "2015-12\n",
      "2016-01\n",
      "2016-02\n",
      "2016-03\n",
      "2016-04\n",
      "2016-05\n",
      "2016-06\n",
      "2016-07\n",
      "2016-08\n",
      "2016-09\n",
      "2016-10\n",
      "2016-11\n",
      "2016-12\n",
      "2017-01\n",
      "2017-02\n",
      "2017-03\n",
      "2017-04\n",
      "2017-05\n",
      "2017-06\n",
      "2017-07\n",
      "2017-08\n",
      "2017-09\n",
      "2017-10\n",
      "2017-11\n",
      "2017-12\n",
      "All data loaded, save to csv\n",
      "SA2 702051066 done\n",
      "SA2 ID: 702051066, Albers tile: 2,-18, SA2 size: 92275.0274km^2, time: ('2015', '2017')\n",
      "2015-01\n",
      "2015-02\n",
      "2015-03\n",
      "2015-04\n",
      "2015-05\n",
      "2015-06\n",
      "2015-07\n",
      "2015-08\n",
      "2015-09\n",
      "2015-10\n",
      "2015-11\n",
      "2015-12\n",
      "2016-01\n",
      "2016-02\n",
      "2016-03\n",
      "2016-04\n",
      "2016-05\n",
      "2016-06\n",
      "2016-07\n",
      "2016-08\n",
      "2016-09\n",
      "2016-10\n",
      "2016-11\n",
      "2016-12\n",
      "2017-01\n",
      "2017-02\n",
      "2017-03\n",
      "2017-04\n",
      "2017-05\n",
      "2017-06\n",
      "2017-07\n",
      "2017-08\n",
      "2017-09\n",
      "2017-10\n",
      "2017-11\n",
      "2017-12\n",
      "All data loaded, save to csv\n",
      "SA2 702051066 done\n",
      "SA2 ID: 702051066, Albers tile: 3,-18, SA2 size: 92275.0274km^2, time: ('2015', '2017')\n",
      "2015-01\n",
      "2015-02\n",
      "2015-03\n",
      "2015-04\n",
      "2015-05\n",
      "2015-06\n",
      "2015-07\n",
      "2015-08\n",
      "2015-09\n",
      "2015-10\n",
      "2015-11\n",
      "2015-12\n",
      "2016-01\n",
      "2016-02\n",
      "2016-03\n",
      "2016-04\n",
      "2016-05\n",
      "2016-06\n",
      "2016-07\n",
      "2016-08\n",
      "2016-09\n",
      "2016-10\n",
      "2016-11\n",
      "2016-12\n",
      "2017-01\n",
      "2017-02\n",
      "2017-03\n",
      "2017-04\n",
      "2017-05\n",
      "2017-06\n",
      "2017-07\n",
      "2017-08\n",
      "2017-09\n",
      "2017-10\n",
      "2017-11\n",
      "2017-12\n",
      "All data loaded, save to csv\n",
      "SA2 702051066 done\n",
      "SA2 ID: 702051066, Albers tile: 4,-18, SA2 size: 92275.0274km^2, time: ('2015', '2017')\n",
      "2015-01\n",
      "2015-02\n",
      "2015-03\n",
      "2015-04\n",
      "2015-05\n",
      "2015-06\n",
      "2015-07\n",
      "2015-08\n",
      "2015-09\n",
      "2015-10\n",
      "2015-11\n",
      "2015-12\n",
      "2016-01\n",
      "2016-02\n",
      "2016-03\n",
      "2016-04\n",
      "2016-05\n",
      "2016-06\n",
      "2016-07\n",
      "2016-08\n",
      "2016-09\n",
      "2016-10\n",
      "2016-11\n",
      "2016-12\n",
      "2017-01\n",
      "2017-02\n",
      "2017-03\n",
      "2017-04\n",
      "2017-05\n",
      "2017-06\n",
      "2017-07\n",
      "2017-08\n",
      "2017-09\n",
      "2017-10\n",
      "2017-11\n",
      "2017-12\n",
      "All data loaded, save to csv\n",
      "SA2 702051066 done\n",
      "SA2 ID: 702051066, Albers tile: 5,-18, SA2 size: 92275.0274km^2, time: ('2015', '2017')\n",
      "2015-01\n",
      "2015-02\n",
      "2015-03\n",
      "2015-04\n",
      "2015-05\n",
      "2015-06\n",
      "2015-07\n",
      "2015-08\n",
      "2015-09\n",
      "2015-10\n",
      "2015-11\n",
      "2015-12\n",
      "2016-01\n",
      "2016-02\n",
      "2016-03\n",
      "2016-04\n",
      "2016-05\n",
      "2016-06\n",
      "2016-07\n",
      "2016-08\n",
      "2016-09\n",
      "2016-10\n",
      "2016-11\n",
      "2016-12\n",
      "2017-01\n",
      "2017-02\n",
      "2017-03\n",
      "2017-04\n",
      "2017-05\n",
      "2017-06\n",
      "2017-07\n",
      "2017-08\n",
      "2017-09\n",
      "2017-10\n",
      "2017-11\n",
      "2017-12\n",
      "All data loaded, save to csv\n",
      "SA2 702051066 done\n",
      "SA2 ID: 702051066, Albers tile: 6,-18, SA2 size: 92275.0274km^2, time: ('2015', '2017')\n",
      "2015-01\n",
      "2015-02\n",
      "2015-03\n",
      "2015-04\n",
      "2015-05\n",
      "2015-06\n",
      "2015-07\n",
      "2015-08\n",
      "2015-09\n",
      "2015-10\n",
      "2015-11\n",
      "2015-12\n",
      "2016-01\n",
      "2016-02\n",
      "2016-03\n",
      "2016-04\n",
      "2016-05\n",
      "2016-06\n",
      "2016-07\n",
      "2016-08\n",
      "2016-09\n",
      "2016-10\n",
      "2016-11\n",
      "2016-12\n",
      "2017-01\n",
      "2017-02\n",
      "2017-03\n",
      "2017-04\n",
      "2017-05\n",
      "2017-06\n",
      "2017-07\n",
      "2017-08\n",
      "2017-09\n",
      "2017-10\n",
      "2017-11\n",
      "2017-12\n",
      "All data loaded, save to csv\n",
      "SA2 702051066 done\n",
      "SA2 ID: 702051066, Albers tile: 3,-19, SA2 size: 92275.0274km^2, time: ('2015', '2017')\n",
      "2015-01\n",
      "2015-02\n",
      "2015-03\n",
      "2015-04\n",
      "2015-05\n",
      "2015-06\n",
      "2015-07\n",
      "2015-08\n",
      "2015-09\n",
      "2015-10\n",
      "2015-11\n",
      "2015-12\n",
      "2016-01\n",
      "2016-02\n",
      "2016-03\n",
      "2016-04\n",
      "2016-05\n",
      "2016-06\n",
      "2016-07\n",
      "2016-08\n",
      "2016-09\n",
      "2016-10\n",
      "2016-11\n",
      "2016-12\n",
      "2017-01\n",
      "2017-02\n",
      "2017-03\n",
      "2017-04\n",
      "2017-05\n",
      "2017-06\n",
      "2017-07\n",
      "2017-08\n",
      "2017-09\n",
      "2017-10\n",
      "2017-11\n",
      "2017-12\n",
      "All data loaded, save to csv\n",
      "SA2 702051066 done\n",
      "SA2 ID: 702051066, Albers tile: 4,-19, SA2 size: 92275.0274km^2, time: ('2015', '2017')\n",
      "2015-01\n",
      "2015-02\n",
      "2015-03\n",
      "2015-04\n",
      "2015-05\n",
      "2015-06\n",
      "2015-07\n",
      "2015-08\n",
      "2015-09\n",
      "2015-10\n",
      "2015-11\n",
      "2015-12\n",
      "2016-01\n",
      "2016-02\n",
      "2016-03\n",
      "2016-04\n",
      "2016-05\n",
      "2016-06\n",
      "2016-07\n",
      "2016-08\n",
      "2016-09\n",
      "2016-10\n",
      "2016-11\n",
      "2016-12\n",
      "2017-01\n",
      "2017-02\n",
      "    No data for 2017-02 , skipping...\n",
      "2017-03\n",
      "2017-04\n",
      "2017-05\n",
      "2017-06\n",
      "2017-07\n",
      "2017-08\n",
      "2017-09\n",
      "2017-10\n",
      "2017-11\n",
      "2017-12\n",
      "All data loaded, save to csv\n",
      "SA2 702051066 done\n",
      "SA2 ID: 702051066, Albers tile: 5,-19, SA2 size: 92275.0274km^2, time: ('2015', '2017')\n",
      "2015-01\n",
      "2015-02\n",
      "2015-03\n",
      "2015-04\n",
      "2015-05\n",
      "2015-06\n",
      "2015-07\n",
      "2015-08\n",
      "2015-09\n",
      "2015-10\n",
      "2015-11\n",
      "2015-12\n",
      "2016-01\n",
      "2016-02\n",
      "2016-03\n",
      "2016-04\n",
      "2016-05\n",
      "2016-06\n",
      "2016-07\n",
      "2016-08\n",
      "2016-09\n",
      "2016-10\n",
      "2016-11\n",
      "2016-12\n",
      "2017-01\n",
      "2017-02\n",
      "2017-03\n",
      "2017-04\n",
      "2017-05\n",
      "2017-06\n",
      "2017-07\n",
      "2017-08\n",
      "2017-09\n",
      "2017-10\n",
      "2017-11\n",
      "2017-12\n",
      "All data loaded, save to csv\n",
      "SA2 702051066 done\n",
      "SA2 ID: 702051066, Albers tile: 6,-19, SA2 size: 92275.0274km^2, time: ('2015', '2017')\n",
      "2015-01\n",
      "2015-02\n",
      "2015-03\n",
      "2015-04\n",
      "2015-05\n",
      "2015-06\n",
      "2015-07\n",
      "2015-08\n",
      "2015-09\n",
      "2015-10\n",
      "2015-11\n",
      "2015-12\n",
      "2016-01\n",
      "2016-02\n",
      "2016-03\n",
      "2016-04\n",
      "2016-05\n",
      "2016-06\n",
      "2016-07\n",
      "2016-08\n",
      "2016-09\n",
      "2016-10\n",
      "2016-11\n",
      "2016-12\n",
      "2017-01\n",
      "2017-02\n",
      "2017-03\n",
      "2017-04\n",
      "2017-05\n",
      "2017-06\n",
      "2017-07\n",
      "2017-08\n",
      "2017-09\n",
      "2017-10\n",
      "2017-11\n",
      "2017-12\n",
      "All data loaded, save to csv\n",
      "SA2 702051066 done\n"
     ]
    }
   ],
   "source": [
    "#save batch/run information\n",
    "run_start = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "count_of_sa2_complete = 0\n",
    "count_of_sa2_error = 0\n",
    "count_of_sa2_all = 0\n",
    "sa2_min_size = 500_0000\n",
    "sa2_max_size = 0\n",
    "batch_start_information = pd.DataFrame([[name_of_output_file],[run_notes],[initials],[run_start]]).T\n",
    "#append batch information to csv in order to record the start of the run\n",
    "batch_start_information.to_csv(f\"{output_path}/tabulate_FC_run_log.csv\",mode='a',header=False) \n",
    "\n",
    "#run the tabulation script for all of the tiled SA2 polygons\n",
    "for geometry, properties in shapes:\n",
    "    count_of_sa2_all += 1\n",
    "    \n",
    "    #save information from shapefile\n",
    "    sa2_id = str(properties['SA2_MAIN16'])\n",
    "    sa2_name = str(properties['SA2_NAME16'])\n",
    "    sa2_size = str(properties['AREASQKM16'])\n",
    "    albers_id = str(properties['label'])\n",
    "    print(f\"SA2 ID: {sa2_id}, Albers tile: {albers_id}, SA2 size: {sa2_size}km^2, time: {time_range}\")\n",
    "        \n",
    "    #loop through SA2 size and save the smallest and largest SA2 values\n",
    "    if float(sa2_min_size) > float(sa2_size):\n",
    "        sa2_min_size = sa2_size\n",
    "    if float(sa2_max_size) < float(sa2_size):\n",
    "        sa2_max_size = sa2_size\n",
    "    \n",
    "    #process fc tabulation\n",
    "    try:\n",
    "        process_area(geometry, sa2_id, sa2_name, sa2_size, albers_id, name_of_output_file, time_range)\n",
    "        count_of_sa2_complete += 1      \n",
    "    #if there are errors, save information to csv to record the name of SA2 and type of error\n",
    "    except Exception as e:\n",
    "            print(f\"Could not process {sa2_id}: {e}\")\n",
    "            error_information = pd.DataFrame([[name_of_output_file],[sa2_id],[time_range], [e]]).T\n",
    "            error_information.to_csv(f\"{output_path}/{name_of_output_file}_error_log.csv\",mode='a',header=False)\n",
    "            count_of_sa2_error += 1\n",
    "            \n",
    "            \n",
    "#save batch/run information\n",
    "run_end = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "run_seconds = (datetime.strptime(run_end,'%Y-%m-%d %H:%M:%S') - datetime.strptime(run_start,'%Y-%m-%d %H:%M:%S')).total_seconds()\n",
    "\n",
    "#save run/batch information to csv\n",
    "batch_information = pd.DataFrame([[name_of_output_file],[run_notes],[initials],\n",
    "                                  [run_start],[run_end],[run_seconds],[sa2_max_size],\n",
    "                                  [sa2_min_size],[time_range],[count_of_sa2_all],\n",
    "                                  [count_of_sa2_complete], [count_of_sa2_error],]).T\n",
    "#output batch information to record the end of the run\n",
    "batch_information.to_csv(f\"{output_path}/tabulate_FC_run_log.csv\",mode='a',header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Combine results for tiled SA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T13:51:32.915512Z",
     "start_time": "2019-06-11T13:51:29.544545Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#read area results of previous workflow and combine tiled results for each SA2\n",
    "\n",
    "#read csv results and format into csv\n",
    "df_in = pd.read_csv(f\"{output_path}/{name_of_output_file}_monthly.csv\", header=0)\n",
    "df_in['DATE'] = pd.to_datetime(df_in['DATE'])\n",
    "df = df_in[['DATE','SA2_MAIN16', 'SA2_NAME16','ALBERS3577_ID', 'AREASQKM16',\n",
    "            'PV_AREA_SQKM_ALBERS3577','NPV_AREA_SQKM_ALBERS3577',\n",
    "           'BS_AREA_SQKM_ALBERS3577','WOFL_AREA_SQKM_ALBERS3577',\n",
    "            'FC_AREA_SQKM_ALBERS3577','AVERAGE_OBSERVATION_COUNT','SA2_TILE_PIXEL_COUNT']]\n",
    "\n",
    "#group data to combine tiled results into whole of sa2 results\n",
    "df = df.groupby(['SA2_MAIN16','DATE','SA2_NAME16','AREASQKM16']).sum()\n",
    "\n",
    "#calculate the percentage of each FC componenet in relation to the whole size of SA2\n",
    "df['PV_PERCENTAGE']= df.PV_AREA_SQKM_ALBERS3577/df.FC_AREA_SQKM_ALBERS3577 *100\n",
    "df['NPV_PERCENTAGE']= df.NPV_AREA_SQKM_ALBERS3577/df.FC_AREA_SQKM_ALBERS3577 *100\n",
    "df['BS_PERCENTAGE']= df.BS_AREA_SQKM_ALBERS3577/df.FC_AREA_SQKM_ALBERS3577 *100\n",
    "df['WOFL_PERCENTAGE']= df.WOFL_AREA_SQKM_ALBERS3577/df.FC_AREA_SQKM_ALBERS3577 *100\n",
    "\n",
    "#calculate the percentage of SA2 that isn't classified as fc components (e.g. cloud)\n",
    "df['UNCLASSIFIED_PERCENTAGE']= 100 - (df.PV_PERCENTAGE + df.NPV_PERCENTAGE + df.BS_PERCENTAGE + df.WOFL_PERCENTAGE)\n",
    "unclass_area = df['UNCLASSIFIED_PERCENTAGE'] * (df['FC_AREA_SQKM_ALBERS3577']/100)\n",
    "#reformat results\n",
    "df.insert(7,'UNCLASSIFIED_AREA_SQKM_ALBERS3577',unclass_area)\n",
    "df = df.reset_index(level=['DATE','AREASQKM16','SA2_NAME16'])\n",
    "\n",
    "#calculate the \"no data\" quality metric\n",
    "no_data_qm = df.groupby([df.SA2_NAME16, df.DATE.dt.year]).count()\n",
    "no_data_qm = no_data_qm.iloc[:,:1]\n",
    "no_data_qm.rename(columns={'DATE':'MONTHS_WITH_NO_DATA'},inplace=True)\n",
    "no_data_qm = 12 - no_data_qm\n",
    "\n",
    "#remove all months that contain >10% unclassified\n",
    "df = df.where(df.UNCLASSIFIED_PERCENTAGE <= 10).dropna()\n",
    "\n",
    "#take a mean of all months within each year\n",
    "annual_df = df.groupby([df.SA2_NAME16, df.DATE.dt.year]).mean()\n",
    "\n",
    "#calculate \"low data\" quality metric\n",
    "low_data_qm = df.groupby([df.SA2_NAME16, df.DATE.dt.year]).count()\n",
    "low_data_qm = low_data_qm.iloc[:,:1]\n",
    "low_data_qm.rename(columns={'DATE':'MONTHS_WITH_LOW_DATA'},inplace=True)\n",
    "low_data_qm = 12 - low_data_qm\n",
    "\n",
    "#Concetenate fc, and quality metrics together\n",
    "annual_df_with_qm = pd.concat([annual_df,low_data_qm, no_data_qm],axis=1,join='inner')\n",
    "\n",
    "#calculate \"average observation quality metric\"\n",
    "ave_obs_qm = df.groupby([df.SA2_NAME16, df.DATE.dt.year]).sum()['AVERAGE_OBSERVATION_COUNT'] \n",
    "ave_obs_qm = ave_obs_qm/(annual_df_with_qm['SA2_TILE_PIXEL_COUNT']/100)\n",
    "\n",
    "#reformat and add the average observation count metric\n",
    "annual_df_with_qm.pop('AVERAGE_OBSERVATION_COUNT')\n",
    "annual_df_with_qm ['AVERAGE_OBSERVATION_COUNT'] = ave_obs_qm\n",
    "annual_df_with_qm.pop('SA2_TILE_PIXEL_COUNT')\n",
    "\n",
    "#save annual results as csv\n",
    "annual_df_with_qm.to_csv(f'{output_path}/{name_of_output_file}_annual.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T13:51:32.959843Z",
     "start_time": "2019-06-11T13:51:32.922297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>AREASQKM16</th>\n",
       "      <th>PV_AREA_SQKM_ALBERS3577</th>\n",
       "      <th>NPV_AREA_SQKM_ALBERS3577</th>\n",
       "      <th>BS_AREA_SQKM_ALBERS3577</th>\n",
       "      <th>WOFL_AREA_SQKM_ALBERS3577</th>\n",
       "      <th>FC_AREA_SQKM_ALBERS3577</th>\n",
       "      <th>UNCLASSIFIED_AREA_SQKM_ALBERS3577</th>\n",
       "      <th>PV_PERCENTAGE</th>\n",
       "      <th>NPV_PERCENTAGE</th>\n",
       "      <th>BS_PERCENTAGE</th>\n",
       "      <th>WOFL_PERCENTAGE</th>\n",
       "      <th>UNCLASSIFIED_PERCENTAGE</th>\n",
       "      <th>MONTHS_WITH_LOW_DATA</th>\n",
       "      <th>MONTHS_WITH_NO_DATA</th>\n",
       "      <th>AVERAGE_OBSERVATION_COUNT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SA2_NAME16</th>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Gulf</th>\n",
       "      <th>2015</th>\n",
       "      <td>92275.0274</td>\n",
       "      <td>24080.518099</td>\n",
       "      <td>47414.373113</td>\n",
       "      <td>19199.927020</td>\n",
       "      <td>328.338511</td>\n",
       "      <td>92274.991875</td>\n",
       "      <td>1251.835131</td>\n",
       "      <td>26.096473</td>\n",
       "      <td>51.383774</td>\n",
       "      <td>20.807292</td>\n",
       "      <td>0.355826</td>\n",
       "      <td>1.356635</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32.450554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>92275.0274</td>\n",
       "      <td>28516.000096</td>\n",
       "      <td>45392.308811</td>\n",
       "      <td>16061.347635</td>\n",
       "      <td>469.227145</td>\n",
       "      <td>92274.991875</td>\n",
       "      <td>1836.108189</td>\n",
       "      <td>30.903281</td>\n",
       "      <td>49.192428</td>\n",
       "      <td>17.405959</td>\n",
       "      <td>0.508510</td>\n",
       "      <td>1.989822</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.970245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>92275.0274</td>\n",
       "      <td>30991.714434</td>\n",
       "      <td>45631.432425</td>\n",
       "      <td>13103.414602</td>\n",
       "      <td>540.366143</td>\n",
       "      <td>92274.991875</td>\n",
       "      <td>2008.064270</td>\n",
       "      <td>33.586255</td>\n",
       "      <td>49.451570</td>\n",
       "      <td>14.200396</td>\n",
       "      <td>0.585604</td>\n",
       "      <td>2.176174</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>33.602095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AREASQKM16  PV_AREA_SQKM_ALBERS3577  \\\n",
       "SA2_NAME16 DATE                                        \n",
       "Gulf       2015  92275.0274             24080.518099   \n",
       "           2016  92275.0274             28516.000096   \n",
       "           2017  92275.0274             30991.714434   \n",
       "\n",
       "                 NPV_AREA_SQKM_ALBERS3577  BS_AREA_SQKM_ALBERS3577  \\\n",
       "SA2_NAME16 DATE                                                      \n",
       "Gulf       2015              47414.373113             19199.927020   \n",
       "           2016              45392.308811             16061.347635   \n",
       "           2017              45631.432425             13103.414602   \n",
       "\n",
       "                 WOFL_AREA_SQKM_ALBERS3577  FC_AREA_SQKM_ALBERS3577  \\\n",
       "SA2_NAME16 DATE                                                       \n",
       "Gulf       2015                 328.338511             92274.991875   \n",
       "           2016                 469.227145             92274.991875   \n",
       "           2017                 540.366143             92274.991875   \n",
       "\n",
       "                 UNCLASSIFIED_AREA_SQKM_ALBERS3577  PV_PERCENTAGE  \\\n",
       "SA2_NAME16 DATE                                                     \n",
       "Gulf       2015                        1251.835131      26.096473   \n",
       "           2016                        1836.108189      30.903281   \n",
       "           2017                        2008.064270      33.586255   \n",
       "\n",
       "                 NPV_PERCENTAGE  BS_PERCENTAGE  WOFL_PERCENTAGE  \\\n",
       "SA2_NAME16 DATE                                                   \n",
       "Gulf       2015       51.383774      20.807292         0.355826   \n",
       "           2016       49.192428      17.405959         0.508510   \n",
       "           2017       49.451570      14.200396         0.585604   \n",
       "\n",
       "                 UNCLASSIFIED_PERCENTAGE  MONTHS_WITH_LOW_DATA  \\\n",
       "SA2_NAME16 DATE                                                  \n",
       "Gulf       2015                 1.356635                     3   \n",
       "           2016                 1.989822                     1   \n",
       "           2017                 2.176174                     2   \n",
       "\n",
       "                 MONTHS_WITH_NO_DATA  AVERAGE_OBSERVATION_COUNT  \n",
       "SA2_NAME16 DATE                                                  \n",
       "Gulf       2015                    0                  32.450554  \n",
       "           2016                    0                  30.970245  \n",
       "           2017                    0                  33.602095  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check annual results\n",
    "annual_df_with_qm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
